# -*- coding: utf-8 -*-
"""prototype diabities.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KWbncv8TU2McLHKEKTIigl55Kfo2QvmN
"""

!pip install --upgrade numpy scikeras lightgbm catboost xgboost shap tensorflow

!pip install tensorflow==2.18.0 --force-reinstall

!pip install --upgrade numpy
!pip uninstall -y catboost
!pip install --no-cache-dir catboost

!pip uninstall -y numpy

!pip install numpy==1.26.4

!pip uninstall -y catboost
!pip install --no-cache-dir catboost

import numpy as np
import tensorflow as tf
import catboost
print("NumPy Version:", np.__version__)
print("TensorFlow Version:", tf.__version__)
print("CatBoost Version:", catboost.__version__)

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from scikeras.wrappers import KerasClassifier  # Corrected import for TensorFlow 2.x
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Load dataset (modify path if needed)
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

# Split features and target variable
X = diabetes_dataset.drop(columns='Outcome', axis=1)
y = diabetes_dataset['Outcome']

# Split the data into train & test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Data successfully loaded and preprocessed!")

# Initialize models
xgb_model = XGBClassifier()
lgbm_model = LGBMClassifier()
cat_model = CatBoostClassifier(verbose=0)

# Train models
xgb_model.fit(X_train, y_train)
lgbm_model.fit(X_train, y_train)
cat_model.fit(X_train, y_train)

print("Models trained successfully!")

from sklearn.ensemble import VotingClassifier

# Create a voting ensemble
voting_ensemble = VotingClassifier(
    estimators=[('xgb', xgb_model), ('lgbm', lgbm_model), ('catboost', cat_model)],
    voting='soft'  # Soft voting for better accuracy
)

# Train ensemble
voting_ensemble.fit(X_train, y_train)

# Evaluate ensemble
y_pred = voting_ensemble.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nVoting Ensemble Accuracy: {accuracy:.4f}")

# Define the neural network model
def create_neural_network(input_dim):
    model = Sequential([
        Dense(128, activation='relu', input_dim=input_dim),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')  # Binary classification
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Train the neural network
nn_model = create_neural_network(X_train.shape[1])
nn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

print("Neural Network trained successfully!")

models = {
    'XGBoost': xgb_model,
    'LightGBM': lgbm_model,
    'CatBoost': cat_model,
    'Voting Ensemble': voting_ensemble
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\n{name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))

# Evaluate Neural Network
nn_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)[1]
print(f"\nNeural Network Accuracy: {nn_accuracy:.4f}")

!pip install shap

import shap
import matplotlib.pyplot as plt

# Use the best model for feature importance (e.g., XGBoost)
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_test)

# Plot feature importance
shap.summary_plot(shap_values, X_test, feature_names=list(diabetes_dataset.columns[:-1]))

import numpy as np

def predict_disease(input_data, model=voting_ensemble, scaler=scaler):
    """
    Predicts disease presence and probability based on user input.

    Parameters:
    - input_data: List or NumPy array with patient details
    - model: Trained machine learning model (default = voting_ensemble)
    - scaler: StandardScaler object for preprocessing

    Returns:
    - Prediction: 0 (No Disease) or 1 (Disease)
    - Probability: Confidence of disease presence
    """
    # Convert input to NumPy array and reshape
    input_data = np.array(input_data).reshape(1, -1)

    # Scale the input data
    scaled_input = scaler.transform(input_data)

    # Predict disease
    prediction = model.predict(scaled_input)[0]
    probability = model.predict_proba(scaled_input)[0][1]  # Probability of having the disease

    return prediction, probability

# Example usage
sample_input = [5, 166, 72, 19, 175, 25.8, 0.587, 51]  # Example patient data
prediction, probability = predict_disease(sample_input)

print(f"Prediction: {'Diseased' if prediction == 1 else 'Not Diseased'}")
print(f"Probability of Disease: {probability:.4f}")

def predict_disease(input_data, model=voting_ensemble, scaler=scaler):
    """
    Predicts disease presence, categorizes risk level, and provides health recommendations.

    Returns:
    - Prediction: 0 (No Disease) or 1 (Disease)
    - Probability: Percentage format (e.g., 92.3%)
    - Risk Level: 'Not Risky', 'Careful', or 'Risky'
    - Recommendation: Lifestyle & healthcare advice based on risk level
    """

    # Convert input to NumPy array and reshape
    input_data = np.array(input_data).reshape(1, -1)

    # Scale the input data
    scaled_input = scaler.transform(input_data)

    # Make prediction
    prediction = model.predict(scaled_input)[0]
    probability = model.predict_proba(scaled_input)[0][1]  # Probability of disease presence

    # Convert probability to percentage
    probability_percentage = round(probability * 100, 2)

    # Categorize risk level and provide recommendations
    if probability_percentage < 40:
        risk_level = "Not Risky"
        recommendation = (
            "âœ… Maintain a balanced diet rich in fruits, vegetables, and whole grains.\n"
            "âœ… Engage in regular physical activity (30 minutes daily).\n"
            "âœ… Get regular check-ups to stay healthy.\n"
            "âœ… Continue healthy lifestyle habits."
        )
    elif 40 <= probability_percentage < 70:
        risk_level = "Careful"
        recommendation = (
            "âš ï¸ You are at moderate risk. Consider the following:\n"
            "ðŸ”¹ Reduce sugar and processed foods in your diet.\n"
            "ðŸ”¹ Increase daily exercise (walking, jogging, or yoga).\n"
            "ðŸ”¹ Monitor your blood pressure and glucose levels regularly.\n"
            "ðŸ”¹ Consider consulting a doctor for preventive measures."
        )
    else:
        risk_level = "Risky"
        recommendation = (
            "ðŸš¨ High risk detected! Immediate action recommended:\n"
            "âš¡ Consult a doctor for a medical check-up as soon as possible.\n"
            "âš¡ Follow a strict diet (low sugar, low sodium, high fiber).\n"
            "âš¡ Engage in moderate exercise (under medical supervision).\n"
            "âš¡ Avoid smoking, alcohol, and high-stress activities.\n"
            "âš¡ Regularly monitor health vitals and seek professional guidance."
        )

    return prediction, probability_percentage, risk_level, recommendation

# Example usage
sample_input = [5, 166, 72, 19, 175, 25.8, 0.587, 51]  # Example patient data
prediction, probability, risk_level, recommendation = predict_disease(sample_input)

print(f"Prediction: {'Diseased' if prediction == 1 else 'Not Diseased'}")
print(f"Probability of Disease: {probability}%")
print(f"Risk Level: {risk_level}")
print("\nðŸ’¡ Recommended Actions:")
print(recommendation)

import joblib

# Save the trained ensemble model
joblib.dump(voting_ensemble, 'voting_ensemble.sav')

#  Save the scaler for preprocessing
joblib.dump(scaler, 'scaler.sav')

print("\nâœ… Model and scaler saved successfully!")