# -*- coding: utf-8 -*-
"""heart final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j9d7OwAODkuhskom4459V5C93hkkDGlN
"""

!pip install scikeras

!pip install catboost

!pip uninstall -y numpy

!pip install numpy==1.26.0

!pip uninstall -y catboost

!pip uninstall -y catboost

!pip install numpy==1.26.0

!pip install catboost==1.2.7

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from scikeras.wrappers import KerasClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.ensemble import VotingClassifier
import shap
import matplotlib.pyplot as plt

# Load dataset
dataset_path = '/content/heart.csv'
heart_dataset = pd.read_csv(dataset_path)

# Split features and target variable
X = heart_dataset.drop(columns='target', axis=1)
y = heart_dataset['target']

# Split the data into train & test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
print("Data successfully loaded and preprocessed!")

# Initialize models
xgb_model = XGBClassifier()
lgbm_model = LGBMClassifier()
cat_model = CatBoostClassifier(verbose=0)

# Train models
xgb_model.fit(X_train, y_train)
lgbm_model.fit(X_train, y_train)
cat_model.fit(X_train, y_train)
print("Models trained successfully!")

# Create a voting ensemble
voting_ensemble = VotingClassifier(
    estimators=[('xgb', xgb_model), ('lgbm', lgbm_model), ('catboost', cat_model)],
    voting='soft'
)
voting_ensemble.fit(X_train, y_train)

# Evaluate ensemble
y_pred = voting_ensemble.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nVoting Ensemble Accuracy: {accuracy:.4f}")

# Define the neural network model
def create_neural_network(input_dim):
    model = Sequential([
        Dense(128, activation='relu', input_dim=input_dim),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Train the neural network
nn_model = create_neural_network(X_train.shape[1])
nn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)
print("Neural Network trained successfully!")

# Evaluate models
models = {
    'XGBoost': xgb_model,
    'LightGBM': lgbm_model,
    'CatBoost': cat_model,
    'Voting Ensemble': voting_ensemble
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\n{name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))

nn_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)[1]
print(f"\nNeural Network Accuracy: {nn_accuracy:.4f}")

# Feature importance with SHAP
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test, feature_names=list(heart_dataset.columns[:-1]))

def predict_heart_disease(input_data, model_path='voting_ensemble.sav', scaler_path='scaler.sav'):
    import joblib

    # ✅ Load the trained model
    model = joblib.load(model_path)

    # ✅ Load the trained scaler
    scaler = joblib.load(scaler_path)

    # ✅ Preprocess the input
    input_data = np.array(input_data).reshape(1, -1)
    scaled_input = scaler.transform(input_data)

    # ✅ Make prediction
    prediction = model.predict(scaled_input)[0]
    probability = model.predict_proba(scaled_input)[0][1] * 100  # Probability %

    # ✅ Risk assessment
    if probability < 40:
        risk_level = "Not Risky"
        recommendation = "✅ Maintain a healthy diet and regular exercise."
    elif 40 <= probability < 70:
        risk_level = "Careful"
        recommendation = "⚠️ Monitor health regularly and consult a doctor."
    else:
        risk_level = "Risky"
        recommendation = "🚨 Seek immediate medical advice."

    return prediction, probability, risk_level, recommendation

import joblib

# ✅ Save the trained ensemble model
joblib.dump(voting_ensemble, 'voting_ensemble.sav')

# ✅ Save the scaler for preprocessing
joblib.dump(scaler, 'scaler.sav')

print("\n✅ Model and scaler saved successfully!")

sample_input = [63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]

prediction, probability, risk_level, recommendation = predict_heart_disease(sample_input)

print(f"Prediction: {'Diseased' if prediction == 1 else 'Not Diseased'}")
print(f"Probability of Disease: {probability:.2f}%")
print(f"Risk Level: {risk_level}")
print("\n💡 Recommended Actions:")
print(recommendation)

